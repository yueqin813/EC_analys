{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14a79aa-29a0-4738-b1ef-989746b335dc",
   "metadata": {},
   "source": [
    "# This script is created by Yue on 4/26/23.\n",
    "\n",
    "Workflow:\n",
    "1. Load original instant data of ux,uy,uz.\n",
    "2. Filter by missing counts, flags.\n",
    "3. Calculate air density.\n",
    "4. Despike.\n",
    "5. Calculate wind angle and qc flag.\n",
    "6. Tilt rotation.\n",
    "7. Detrend.\n",
    "8. Density correction. (neglect)\n",
    "9. Spectral correction. (neglect)\n",
    "10. Quality control.\n",
    "\n",
    "Note:\\\n",
    "q,P measurements are very weird so I didn't perform de-spiking on them.\\\n",
    "qc=0: data is good; =1: data is bad.\\\n",
    "webb_corr=1: correct q,T,C; =2: correct q,C; =0: no correction.\\\n",
    "Do high-pass filtering on u,v,w,T with the same cutoff wavelength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee5de0-50ad-48c4-a750-5304928d7e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de32405f-c9b7-4a3a-95bf-54b240dc8e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This jupyter notebook command inserts matplotlib graphics in to the workbook\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pickle\n",
    "import time\n",
    "from matplotlib.pyplot import figure\n",
    "import scipy.io as sio\n",
    "from datetime import date, timedelta\n",
    "from math import *\n",
    "from scipy.stats import gmean\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter,sosfiltfilt,filtfilt\n",
    "from scipy import fftpack\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3e231-fa3b-4287-a626-9fda3fd4a8a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e61de0b-cec2-4173-bdb3-d820c3555e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directories\n",
    "IN_DIR = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/processed_data/\"\n",
    "OUT_DIR = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/processed_data_020724/\"\n",
    "# Neutral_DIRECTORY = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/neutral_data_20200925_20210423/\"\n",
    "# FIG_DIR = '/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/fig_neutral/'\n",
    "\n",
    "# physical constants (or values that are assumed constant)\n",
    "Rw  = 461.5     # ideal gas constant for water vapor, J/kg*K\n",
    "Rd  = 287.05    # ideal gas constant for dry air, J/kg*K\n",
    "Lv  = 1000*2257 # latent heat of vaporization (water), J/kg\n",
    "Cp  = 1005      # approximate constant pressure specific heat of air, J/kg*K\n",
    "k   = 0.4      # Von Karman constant\n",
    "g   = 9.81      # acceleration of gravity, m/s^2\n",
    "\n",
    "# global constants\n",
    "sonum    =12                       # number of sonic\n",
    "z  = np.array([1.2,2,3.5,6,9,12.5,16.5,23,30,40,50,60])  # height of sonic above ground, \n",
    "frequency=10                   # sampling rate, Hz\n",
    "time_avg =3600                  # average time, s\n",
    "rpat = time_avg*frequency           # number of lines for a loop\n",
    "A1 = 1 # constants in Townsend's formulations for the normalized standard deviation of horizontal velocity\n",
    "B1 = 2.5\n",
    "min_wnd  = 120\n",
    "max_wnd  = 240 \n",
    "\n",
    "# Filter requirements.\n",
    "T = time_avg         # Sample Period\n",
    "l_cutoff = 2000      # cutoff wavelength, m\n",
    "order = 10       # filter order\n",
    "nyq = 0.5 * frequency  # Nyquist Frequency\n",
    "n = int(T * frequency) # total number of samples\n",
    "\n",
    "# variables\n",
    "# day = date(2021,4,10)\n",
    "list_all = np.arange(0,12)\n",
    "ins_var=['u_ins','v_ins','w_ins','Tsonic_ins','q_ins','P_ins','diag_csat_ins']\n",
    "\n",
    "# output variables\n",
    "out_tur = ['ux_dspk', 'uy_dspk', 'uz_dspk', 'T_dspk',\n",
    "           'u_dspk_2rot_ldtr', 'v_dspk_2rot_ldtr', 'w_dspk_2rot_ldtr', 'T_dspk_ldtr', \n",
    "           'u_dspk_2rot_trend', 'v_dspk_2rot_trend', 'w_dspk_2rot_trend', 'T_dspk_trend',\n",
    "           'u_dspk_2rot_filt', 'v_dspk_2rot_filt', 'w_dspk_2rot_filt', 'T_dspk_filt',\n",
    "           'u_tur_ldtr', 'v_tur_ldtr', 'w_tur_ldtr', 'T_tur_ldtr',\n",
    "           'u_tur_filt', 'v_tur_filt', 'w_tur_filt', 'T_tur_filt']\n",
    "out_avg = ['P_avg', 'T_avg', 'q_avg', 'Rho_air', \n",
    "           'u_avg_ldtr', 'v_avg_ldtr', 'w_avg_ldtr', 'T_avg_ldtr', \n",
    "           'u_avg_filt', 'v_avg_filt', 'w_avg_filt', 'T_avg_filt']\n",
    "out_std = ['u_std_ldtr', 'v_std_ldtr', 'w_std_ldtr', 'T_std_ldtr',\n",
    "           'u_std_filt', 'v_std_filt', 'w_std_filt', 'T_std_filt']\n",
    "out_flux = ['uw_ldtr', 'vw_ldtr', 'wT_ldtr', 'u_star_ldtr', 'H_ldtr', \n",
    "            'uw_filt', 'vw_filt', 'wT_filt', 'u_star_filt', 'H_filt']\n",
    "out_other = ['ts_dspk_wind_ang', 'u_filt_size', 'L_H2_ldtr', 'stability_ldtr', 'L_H2_filt', 'stability_filt']\n",
    "out_qf = ['qc_ux_nan', 'qc_uy_nan', 'qc_uz_nan', 'qc_T_nan', 'qc_q_nan', 'qc_P_nan',\n",
    "          'qc_ux_dspk', 'qc_uy_dspk', 'qc_uz_dspk', 'qc_T_dspk','qc_wdir_dspk']\n",
    "out_nspikes = ['u_nspikes', 'v_nspikes', 'w_nspikes', 'T_nspikes']\n",
    "\n",
    "# labels\n",
    "list_bot = np.array([0,1,2,3,4]) # bottom five levels\n",
    "list_sel_m2 = np.array([5,6,7,8,9,10]) # from level 6 to level 11\n",
    "level = ['L1', 'L2', 'L3','L4', 'L5', 'L6','L7', 'L8', 'L9','L10', 'L11', 'L12']\n",
    "\n",
    "# PLOTTING STUFF\n",
    "## define useful fonts\n",
    "plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='sans-serif')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rc('xtick', labelsize=16) \n",
    "plt.rc('ytick', labelsize=16)\n",
    "font_size = 18\n",
    "# ldg = np.array(['B2','B3','B4','A1','A2','A3'])\n",
    "ldg = np.array([\"12.5\",\"16.5\",\"23\",\"30\",\"40\",\"50\"])\n",
    "color_list=sns.color_palette(\"tab10\")\n",
    "\n",
    "# controls\n",
    "# webb_corr = 2 # do webb-corr on q and C only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf678d-9839-42d2-bf16-18d132d57c22",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6592bfe4-587b-49d7-a32e-29d74fbc7d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_list(sdate,edate):\n",
    "    \"\"\"method used for creating date list\"\"\"\n",
    "    delta = edate - sdate       # as timedelta\n",
    "    day = [sdate+timedelta(days=x) for x in range(delta.days+1)]\n",
    "    return day\n",
    "\n",
    "def rmnan(data,flag):  \n",
    "    \"\"\" method used for checking & rm nan\"\"\"  \n",
    "    data[flag >= 65] = np.nan ## ！！！！！ get rid of bad data (thershold is 65)! ! ! ! !\n",
    "    nansum = np.sum(np.isnan(data))\n",
    "    qc = 0\n",
    "    if nansum >= time_avg*frequency/10:\n",
    "        data[:] = np.nan\n",
    "        qc = 1\n",
    "    return data,qc\n",
    "    # for icol in range(sonum):\n",
    "    #     nansum = np.sum(np.isnan(data[:,icol]),0)\n",
    "    #     # if there are more than 10% nan in an hour, discard all data at that level\n",
    "    #     if nansum >= time_avg*frequency/10:\n",
    "    #         data[:,icol] = np.nan\n",
    "    # return data\n",
    "def get_wind_ang(ux,uy,nl):\n",
    "    \"\"\"\n",
    "    !!!arctan return values in radians!!!\n",
    "    for 1 level only\n",
    "    calculate mean wind angle on the xy-plane (!! must do before double rotation)\n",
    "    The CSAT3 (the anemometer arms, tripods) is aligned northward and if u is positive, the wind is northerly. \n",
    "    If v is positive, the wind is westerly.\n",
    "    u:north(+)->south(-), v:west(+)->east(-)\n",
    "    \"\"\"\n",
    "    u_avg = np.nanmean(ux,axis=0) # size = 1\n",
    "    v_avg = np.nanmean(uy,axis=0)\n",
    "    rot_ang_v = degrees(np.arctan(v_avg/u_avg))\n",
    "    # print('nl='+str(nl))\n",
    "    # if nl==2:\n",
    "    #     wind_ang = rot_ang_v*np.nan\n",
    "    #     mask1 = np.logical_and(u_avg>=0, v_avg<=0)\n",
    "    #     wind_ang[mask1] = -rot_ang_v[mask1] # northeast\n",
    "    #     mask2 = np.logical_and(u_avg<=0, v_avg<=0)\n",
    "    #     wind_ang[mask2] = 180-rot_ang_v[mask2] # southest\n",
    "    #     mask3 = np.logical_and(u_avg<=0, v_avg>=0)\n",
    "    #     wind_ang[mask3] = 180-rot_ang_v[mask3] # southwest\n",
    "    #     mask4 = np.logical_and(u_avg>=0, v_avg>=0)\n",
    "    #     wind_ang[mask4] = 360-rot_ang_v[mask4] # northwest         \n",
    "    if nl==1:\n",
    "        wind_ang = rot_ang_v\n",
    "        if np.logical_and(u_avg>=0, v_avg<=0):\n",
    "            wind_ang = -rot_ang_v # northeast\n",
    "        if np.logical_and(u_avg<=0, v_avg<=0):\n",
    "            wind_ang = 180-rot_ang_v # southest\n",
    "        if np.logical_and(u_avg<=0, v_avg>=0):\n",
    "            wind_ang = 180-rot_ang_v # southwest\n",
    "        if np.logical_and(u_avg>=0, v_avg>=0):\n",
    "            wind_ang = 360-rot_ang_v # northwest \n",
    "    return wind_ang\n",
    "\n",
    "def wind_ang(ux,uy):\n",
    "    \"\"\"\n",
    "    calculate mean wind angle on the xy-plane (!! must do before double rotation)\n",
    "    The CSAT3 (the anemometer arms, tripods) is aligned northward and if u is positive, the wind is northerly. \n",
    "    If v is positive, the wind is westerly.\n",
    "    u:north(+)->south(-), v:west(+)->east(-)\n",
    "    \"\"\"\n",
    "    u_avg = np.nanmean(ux,axis=0) # size = 12\n",
    "    v_avg = np.nanmean(uy,axis=0)\n",
    "    rot_ang_v = np.arctan(v_avg/u_avg)\n",
    "    rot_ang_v = rot_ang_v*360/2/math.pi\n",
    "    mask1 = np.logical_and(u_avg>=0, v_avg<=0)\n",
    "    rot_ang_v[mask1] = -rot_ang_v[mask1] # northeast\n",
    "    mask2 = np.logical_and(u_avg<=0, v_avg<=0)\n",
    "    rot_ang_v[mask2] = 180-rot_ang_v[mask2] # southest\n",
    "    mask3 = np.logical_and(u_avg<=0, v_avg>=0)\n",
    "    rot_ang_v[mask3] = 180-rot_ang_v[mask3] # southwest\n",
    "    mask4 = np.logical_and(u_avg>=0, v_avg>=0)\n",
    "    rot_ang_v[mask4] = 360-rot_ang_v[mask4] # northwest\n",
    "    \n",
    "    # quality control: wind angle>120 and < 240\n",
    "    qc = np.zeros(12)\n",
    "    msk = np.logical_and(rot_ang_v> min_wnd,rot_ang_v<max_wnd)\n",
    "    qc[msk] = 1\n",
    "    return rot_ang_v,qc\n",
    "\n",
    "def double_rot(ux,uy,uz):\n",
    "    \"\"\"\n",
    "    Double rotation method (Note yaw correction must perform before pitch correction)\n",
    "    https://www.licor.com/env/support/EddyPro/topics/anemometer-tilt-correction.html#:~:\n",
    "    text=Double%20rotation%20method,by%20the%20flux%20averaging%20length.\n",
    "    # such that the hourly avg of v and w will be zero\n",
    "    # only u,v,w will be rotated, other variables remain the same\n",
    "    \"\"\"\n",
    "    u_avg = np.nanmean(ux,axis=0) # size = 12\n",
    "    v_avg = np.nanmean(uy,axis=0)\n",
    "    w_avg = np.nanmean(uz,axis=0)\n",
    "    # 1) yaw rotation\n",
    "    C1 = (u_avg**2 + v_avg**2) ** 0.5\n",
    "    rot_mat_1 = u_avg/C1\n",
    "    rot_mat_2 = v_avg/C1\n",
    "    rot_mat_3 = -v_avg/C1\n",
    "    rot_mat_4 = u_avg/C1\n",
    "    u_rot = ux * rot_mat_1 + uy*rot_mat_2\n",
    "    v_rot = ux * rot_mat_3 + uy*rot_mat_4\n",
    "    u_ins_yawrot = u_rot\n",
    "    v_ins_2rot = v_rot\n",
    "    u_avg_yawrot = np.nanmean(u_ins_yawrot,axis=0)\n",
    "    # v_avg_2rot = np.nanmean(v_ins_2rot,axis=0)\n",
    "\n",
    "    # 2) pitch rotation\n",
    "    C2 = (u_avg_yawrot**2 + w_avg**2) ** 0.5\n",
    "    rot_mat_1 = u_avg_yawrot/C2\n",
    "    rot_mat_2 = w_avg/C2\n",
    "    rot_mat_3 =-w_avg/C2\n",
    "    rot_mat_4 = u_avg_yawrot/C2\n",
    "    u_rot = u_ins_yawrot * rot_mat_1 + uz*rot_mat_2\n",
    "    w_rot = u_ins_yawrot * rot_mat_3 + uz*rot_mat_4\n",
    "    u_ins_2rot = u_rot\n",
    "    w_ins_2rot = w_rot\n",
    "    # u_avg_2rot = np.nanmean(u_ins_2rot,axis=0)\n",
    "    # w_avg_2rot = np.nanmean(w_ins_2rot,axis=0)\n",
    "    \n",
    "    return u_ins_2rot,v_ins_2rot,w_ins_2rot\n",
    "\n",
    "def butter_lowpass_filter(filt_type, data, cutoff, fs, order):\n",
    "    \"\"\"\n",
    "    The frequency response of the Butterworth filter is maximally flat \n",
    "    (i.e. has no ripples) in the passband and rolls off towards zero in the stopband, \n",
    "    hence its one of the most popular low pass filter.\n",
    "    \n",
    "    data shoule be turbulent component!\n",
    "    \"\"\"\n",
    "    # replace nan by mean value\n",
    "    data[np.argwhere(np.isnan(data))] = np.nanmean(data)\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    sos = butter(order, normal_cutoff, btype=filt_type, analog=False, output='sos',fs=fs)\n",
    "    # Return the filtered output with the same shape as data\n",
    "    # The function sosfiltfilt should be preferred over filtfilt \n",
    "    # for most filtering tasks, as second-order sections have fewer numerical problems.\n",
    "    y = sosfiltfilt(sos, data) \n",
    "    return y\n",
    "\n",
    "def get_u_star(u_tur_in,v_tur_in,w_tur_in):\n",
    "    uw = np.nanmean(u_tur_in*w_tur_in,axis=0)\n",
    "    vw = np.nanmean(v_tur_in*w_tur_in,axis=0)\n",
    "    u_star = (np.maximum(0,(uw**2+vw**2)**0.5))**0.5\n",
    "    return u_star\n",
    "  \n",
    "\n",
    "def dtrd(data):\n",
    "    # Only return the turbulent component  \n",
    "    # The result is equal to signal.detrend(data)+np.mean(data)\n",
    "    ct = np.arange(len(data))\n",
    "    a = -(len(data)*np.nansum(ct*data, axis=0) - np.nansum(ct, axis=0) * \n",
    "          np.nansum(data, axis=0)) / (np.nansum(ct**2, axis=0)-(np.nansum(ct, axis=0))**2)\n",
    "    b = (np.nansum(data, axis=0) - a * np.nansum(ct, axis=0))/len(data)\n",
    "    data_dtr = data + (a*ct+b) - np.nanmean(data)\n",
    "    return data_dtr\n",
    "\n",
    "def get_ist(data):\n",
    "    \"\"\"\n",
    "    Return the non-stationarity index for every hourly time series \n",
    "    \"\"\"\n",
    "    data_5min = data.reshape([12,-1]) # split each hour into 12 chunks/every 5 min\n",
    "    cvm = np.nanmean(np.nanvar(data_5min,axis=1)) # avg of the variance of each chunck\n",
    "    ist_5min = abs(cvm-np.nanvar(data))/np.nanvar(data)\n",
    "    return ist_5min\n",
    "\n",
    "def z_score(intensity):\n",
    "    \"\"\"\n",
    "    Z-score based approach for spike detection\n",
    "    \"\"\"\n",
    "    mean_int = np.nanmean(intensity)\n",
    "    std_int = np.nanstd(intensity)\n",
    "    z_scores = (intensity-mean_int) / std_int\n",
    "    return z_scores\n",
    "\n",
    "def fixer(y,thres):\n",
    "    \"\"\"\n",
    "    remove spikes and fix them with the mean of its immediate neighbors.\n",
    "    Following Vickers and Mahrt (1997), \n",
    "    https://www.licor.com/env/support/EddyPro/topics/despiking-raw-statistical-screening.html\n",
    "    \"\"\"\n",
    "    qc = 0\n",
    "    it = 0\n",
    "    y_original = y.copy()\n",
    "    while it < 20: # iterate 20 times\n",
    "        # print(f\"the {it} iterations:\")\n",
    "        # print(f\"the 0 windows\")\n",
    "        y_sub = y[0:12000] # moving window is 20 min\n",
    "        y_fix = y_sub.copy()\n",
    "        spikes = abs(np.array(z_score(y_sub))) > thres\n",
    "        n_con_spk = 0 # counts of more than 4 consecutive spikes\n",
    "        for i in np.where(spikes != 0)[0]:  # If we have an spike in position i\n",
    "            if i == 12000 - 1:\n",
    "                w2 = np.arange(i-3,i+1)\n",
    "                w1 = w2\n",
    "            elif i == 12000 - 2:\n",
    "                w2 = np.arange(i-4,i)\n",
    "                w1 = np.arange(i-3,i+1)\n",
    "            elif i == 12000 - 3:\n",
    "                w2 = np.arange(i-5,i-1)\n",
    "                w1 = np.arange(i-3,i+1)\n",
    "            else:\n",
    "                w1 = np.arange(i-3,i+1)\n",
    "                w2 = np.arange(i,i+4)\n",
    "            # 4 consecutive outliers\n",
    "            # are considered as a local trend and not counted as a spike. \n",
    "            if np.sum(spikes[w1])==4 or np.sum(spikes[w2])==4:\n",
    "                # print(f\"4 consecutive spikes.\")\n",
    "                n_con_spk += 1\n",
    "            else:\n",
    "                if i == 12000 - 1:\n",
    "                    w = np.arange(12000-3,12000)\n",
    "                else:\n",
    "                    w = np.arange(i-1,i+2) # we select 3 points around our spike\n",
    "                ww = w[spikes[w] == 0] # From such interval, we choose the ones which are not spikes\n",
    "                y_fix[i] = np.mean(y_sub[ww]) # and we average their values\n",
    "        # nspikes = np.nansum(spikes) - n_con_spk\n",
    "        y_new = y_fix\n",
    "        # 2nd to 6th moving window\n",
    "        for iw in np.arange(1,5):\n",
    "            n_con_spk = 0\n",
    "            # print(f\"the {iw} windows\")\n",
    "            y_sub = y[iw*6000:iw*6000+12000]\n",
    "            y_fix = y_sub.copy()\n",
    "            spikes = abs(np.array(z_score(y_sub))) > thres\n",
    "            for i in np.where(spikes != 0)[0]:  # If we have an spike in position i\n",
    "                if i >= 6000:\n",
    "                    if i == 12000 - 1:\n",
    "                        w2 = np.arange(i-3,i+1)\n",
    "                        w1 = w2\n",
    "                    elif i == 12000 - 2:\n",
    "                        w2 = np.arange(i-4,i)\n",
    "                        w1 = np.arange(i-3,i+1)\n",
    "                    elif i == 12000 - 3:\n",
    "                        w2 = np.arange(i-5,i-1)\n",
    "                        w1 = np.arange(i-3,i+1)\n",
    "                    else:\n",
    "                        w1 = np.arange(i-3,i+1)\n",
    "                        w2 = np.arange(i,i+4)\n",
    "                    # 4 consecutive outliers\n",
    "                    # are considered as a local trend and not counted as a spike. \n",
    "                    if np.sum(spikes[w1])==4 or np.sum(spikes[w2])==4:         \n",
    "                        # print(f\"4 consecutive spikes.\")\n",
    "                        n_con_spk += 1\n",
    "                    else:\n",
    "                        if i == 12000 - 1:\n",
    "                            w = np.arange(12000-3,12000)\n",
    "                        else:\n",
    "                            w = np.arange(i-1,i+2) # we select 3 points around our spike\n",
    "                        ww = w[spikes[w] == 0] # From such interval, we choose the ones which are not spikes\n",
    "                        y_fix[i] = np.mean(y_sub[ww]) # and we average their values\n",
    "            nspk = np.nansum(spikes[6000:12000]) - n_con_spk\n",
    "            y_new = np.append(y_new,y_fix[6000:12000])\n",
    "            # nspikes += nspk\n",
    "        # print(f\"{nspikes} spikes\")\n",
    "        # print(\"-----------\")        \n",
    "        # if it == 0:\n",
    "        #     n_spikes = nspikes\n",
    "        # else:\n",
    "        n_spikes = np.sum((y_new-y_original)!=0)\n",
    "        if n_spikes > 0.01*rpat: # accepted spikes is 1%\n",
    "            qc = 1 # quality flag = 1, should be discarded from the results dataset.\n",
    "            print(\"Too much number of spikes\")\n",
    "            break\n",
    "        if n_spikes == 0:\n",
    "            break\n",
    "        y = y_new\n",
    "        it += 1\n",
    "    return y_new,qc,n_spikes\n",
    "\n",
    "\n",
    "def abs_lim(y,lim):\n",
    "    \"\"\"\n",
    "    After de-spiking,\n",
    "    replace a value that is outside a user-defined plausible range \n",
    "    by the mean of neiboring variables. \n",
    "    \"\"\"\n",
    "    out_lier = abs(y)>lim\n",
    "    # print(np.sum(out_lier))\n",
    "    y_lim = y.copy()\n",
    "    for i in np.where(out_lier!=0)[0]:\n",
    "        w = np.arange(i-2,i+3) # select 5 points around \n",
    "        w2 = w[out_lier[w] == 0] # From such interval, we choose the ones which are not outliers\n",
    "        y_lim[i] = np.mean(y[w2]) # and we average their values\n",
    "    return y_lim\n",
    "\n",
    "def CheckForLess(list1, val): \n",
    "    # traverse in the list\n",
    "    for x in list1: \n",
    "        # compare with all the\n",
    "        # values with value\n",
    "        if val <= x:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d48163-845d-4736-b8ef-d3836f8dcf75",
   "metadata": {},
   "source": [
    "# Load data and do the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46e2d844-4e5b-4c4c-948b-6f0b329f5205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up time period and initialize variables\n",
    "Sdate = date(2020,9,25)\n",
    "# Sdate = date(2021,3,2)\n",
    "Edate = date(2021,4,23)\n",
    "# Edate = date(2020,9,26)\n",
    "ds = date_list(Sdate,Edate)\n",
    "write_results = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca274291-6e17-4fd7-9309-c6dbcd5592b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing:20200925\n",
      "start writing results\n",
      "finish:20200925\n",
      "start processing:20200926\n",
      "start writing results\n",
      "finish:20200926\n",
      "start processing:20200927\n",
      "start writing results\n",
      "finish:20200927\n",
      "start processing:20200928\n",
      "start writing results\n",
      "finish:20200928\n",
      "start processing:20200929\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neutral_case = []\n",
    "for day in ds:\n",
    "    strday = str(day.strftime(\"%Y%m%d\"))\n",
    "    fp_stats = IN_DIR + 'u_ins_' + strday +'.pkl'\n",
    "    if (not os.path.isfile(fp_stats)):\n",
    "        print(day.strftime(\"%Y%m%d\")+' do not exist')\n",
    "        continue\n",
    "    print('start processing:'+ strday)\n",
    "    # load data    \n",
    "    for var in ins_var:\n",
    "        a_file = open(IN_DIR + var + '_' + strday +'.pkl', \"rb\")\n",
    "        globals()[var] = pickle.load(a_file)\n",
    "        a_file.close()\n",
    "    u_ins3d = u_ins.reshape(-1,rpat,sonum)\n",
    "    v_ins3d = v_ins.reshape(-1,rpat,sonum)\n",
    "    w_ins3d = w_ins.reshape(-1,rpat,sonum)\n",
    "    T_ins3d = Tsonic_ins.reshape(-1,rpat,sonum)\n",
    "    q_ins3d = q_ins.reshape(-1,rpat,sonum)\n",
    "    P_ins3d = P_ins.reshape(-1,rpat,sonum)\n",
    "    diag_ins3d = diag_csat_ins.reshape(-1,rpat,sonum)\n",
    "  \n",
    "    # data initialization---------------------------\n",
    "    ## initialize qaulity flag to be 0\n",
    "    qc_ux_nan = np.zeros((24,sonum)) \n",
    "    qc_uy_nan = np.zeros((24,sonum))\n",
    "    qc_uz_nan = np.zeros((24,sonum))\n",
    "    qc_T_nan = np.zeros((24,sonum))\n",
    "    qc_q_nan = np.zeros((24,sonum))\n",
    "    qc_P_nan = np.zeros((24,sonum))\n",
    "    \n",
    "    qc_ux_dspk = np.zeros((24,sonum)) \n",
    "    qc_uy_dspk = np.zeros((24,sonum))\n",
    "    qc_uz_dspk = np.zeros((24,sonum))\n",
    "    qc_T_dspk = np.zeros((24,sonum))\n",
    "    \n",
    "    ## number of spikes\n",
    "    u_nspikes = np.zeros((24,sonum)) * np.nan\n",
    "    v_nspikes = np.zeros((24,sonum)) * np.nan\n",
    "    w_nspikes = np.zeros((24,sonum)) * np.nan\n",
    "    T_nspikes = np.zeros((24,sonum)) * np.nan\n",
    "    qc_wdir_dspk = np.zeros((24,sonum))\n",
    "    \n",
    "    ## hourly averaged wind angle\n",
    "    ts_dspk_wind_ang = np.zeros((24,sonum)) * np.nan \n",
    "    ## high-pass filter size\n",
    "    u_filt_size = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    ## mean variables\n",
    "    P_avg = np.zeros((24,sonum)) * np.nan\n",
    "    T_avg = np.zeros((24,sonum)) * np.nan\n",
    "    q_avg = np.zeros((24,sonum)) * np.nan\n",
    "    Rho_air = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    u_avg_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    v_avg_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    w_avg_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    T_avg_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "\n",
    "    u_avg_filt = np.zeros((24,sonum)) * np.nan\n",
    "    v_avg_filt = np.zeros((24,sonum)) * np.nan\n",
    "    w_avg_filt = np.zeros((24,sonum)) * np.nan\n",
    "    T_avg_filt = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    ## tur\n",
    "    ux_dspk = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    uy_dspk = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    uz_dspk = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_dspk = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    \n",
    "    u_dspk_2rot_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    v_dspk_2rot_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    w_dspk_2rot_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_dspk_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    \n",
    "    u_dspk_2rot_trend = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    v_dspk_2rot_trend = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    w_dspk_2rot_trend = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_dspk_trend = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    \n",
    "    u_dspk_2rot_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    v_dspk_2rot_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    w_dspk_2rot_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_dspk_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    \n",
    "    u_tur_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    v_tur_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    w_tur_ldtr = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_tur_ldtr = np.zeros((24,rpat,sonum)) * np.nan \n",
    "    \n",
    "    u_tur_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    v_tur_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    w_tur_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "    T_tur_filt = np.zeros((24,rpat,sonum)) * np.nan\n",
    "\n",
    "    ## std\n",
    "    u_std_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    v_std_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    w_std_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    T_std_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    u_std_filt = np.zeros((24,sonum)) * np.nan\n",
    "    v_std_filt = np.zeros((24,sonum)) * np.nan\n",
    "    w_std_filt = np.zeros((24,sonum)) * np.nan\n",
    "    T_std_filt = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    ## fluxes\n",
    "    uw_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    vw_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    wT_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    u_star_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    H_ldtr = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    uw_filt = np.zeros((24,sonum)) * np.nan\n",
    "    vw_filt = np.zeros((24,sonum)) * np.nan\n",
    "    wT_filt = np.zeros((24,sonum)) * np.nan\n",
    "    u_star_filt = np.zeros((24,sonum)) * np.nan\n",
    "    H_filt = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    ## other variables\n",
    "    ### Obukhov length\n",
    "    L_H2_ldtr = np.zeros((24,sonum)) * np.nan \n",
    "    stability_ldtr  = np.zeros((24,sonum)) * np.nan\n",
    "    L_H2_filt = np.zeros((24,sonum)) * np.nan \n",
    "    stability_filt  = np.zeros((24,sonum)) * np.nan\n",
    "    \n",
    "    ## control flag (False)\n",
    "    mask_neutral = np.zeros(24)\n",
    "    mask_taylor = np.zeros(24)\n",
    "    mask_magnitude = np.zeros(24)\n",
    "    mask_qc = np.zeros(24)\n",
    "    mask_all = np.zeros(24)\n",
    "    \n",
    "    ##-------------------------------------------------\n",
    "    # loop over hours\n",
    "    for ih in range(24): \n",
    "        ux_ts = u_ins3d[ih,:,:] #36000*12\n",
    "        uy_ts = v_ins3d[ih,:,:]\n",
    "        uz_ts = w_ins3d[ih,:,:]\n",
    "        T_ts = T_ins3d[ih,:,:]\n",
    "        q_ts = q_ins3d[ih,:,:]\n",
    "        P_ts = P_ins3d[ih,:,:]\n",
    "        diag = diag_ins3d[ih,:,:]\n",
    "        \n",
    "        # Block 1: remove nan\n",
    "        # start_time = time.time()\n",
    "        # replace the whole chunk by nan if nan exceeds 10% in an hour\n",
    "        # Get rid of bad data with diag_csat >= 65\n",
    "        for il in range(12): # loop over levels\n",
    "            ux_ts[:,il],qc_ux_nan[ih,il] = rmnan(ux_ts[:,il],diag[:,il])\n",
    "            uy_ts[:,il],qc_uy_nan[ih,il] = rmnan(uy_ts[:,il],diag[:,il])\n",
    "            uz_ts[:,il],qc_uz_nan[ih,il] = rmnan(uz_ts[:,il],diag[:,il])\n",
    "            T_ts[:,il],qc_T_nan[ih,il] = rmnan(T_ts[:,il],diag[:,il])\n",
    "            q_ts[:,il],qc_q_nan[ih,il] = rmnan(q_ts[:,il],diag[:,il])\n",
    "            P_ts[:,il],qc_P_nan[ih,il] = rmnan(P_ts[:,il],diag[:,il])\n",
    "        # print('rmnan done')\n",
    "        # 0. calculate air density\n",
    "        P_avg[ih,:] = np.nanmean(P_ts,axis=0) \n",
    "        T_avg[ih,:] = np.nanmean(T_ts,axis=0)\n",
    "        q_avg[ih,:] = np.nanmean(q_ts,axis=0)\n",
    "        Rho_air[ih,:] = P_avg[ih,:]/(287.04*T_avg[ih,:]) - 0.61*q_avg[ih,:]\n",
    "        # fill in missing data\n",
    "        Rho_air[ih,2] = 0.5*(Rho_air[ih,1] +Rho_air[ih,3])\n",
    "        Rho_air[ih,4] = 0.5*(Rho_air[ih,3] +Rho_air[ih,5])   \n",
    "        Rho_air[ih,6] = 0.5*(Rho_air[ih,5] +Rho_air[ih,7])\n",
    "        Rho_air[ih,10] = 0.5*(Rho_air[ih,9] +Rho_air[ih,11]) \n",
    "        # print('Rho done')\n",
    "        # end_time = time.time()\n",
    "        # duration = end_time - start_time\n",
    "        # print(f\"Time taken for remove nan: {duration} seconds\")\n",
    "        \n",
    "        # 1. De-spiking\n",
    "        # start_time = time.time()\n",
    "        for il in range(12): # loop over levels\n",
    "            # if whole chunck is nan then skip de-spiking\n",
    "            if np.any([qc_ux_nan[ih,il],qc_uy_nan[ih,il],qc_uz_nan[ih,il],qc_T_nan[ih,il]]):\n",
    "                continue\n",
    "            else:\n",
    "                ux_dspk[ih,:,il],qc_ux_dspk[ih,il],u_nspikes[ih,il] = fixer(ux_ts[:,il],thres=3.5) # 36000*12, 24*12, 24*12\n",
    "                uy_dspk[ih,:,il],qc_uy_dspk[ih,il],v_nspikes[ih,il] = fixer(uy_ts[:,il],thres=3.5)\n",
    "                uz_dspk[ih,:,il],qc_uz_dspk[ih,il],w_nspikes[ih,il] = fixer(uz_ts[:,il],thres=5)\n",
    "                T_dspk[ih,:,il],qc_T_dspk[ih,il],T_nspikes[ih,il] = fixer(T_ts[:,il],thres=3.5)\n",
    "        # print('despike done')  \n",
    "        # end_time = time.time()\n",
    "        # duration = end_time - start_time\n",
    "        # print(f\"Time taken for dspk: {duration} seconds\")\n",
    "        \n",
    "        # 2. Wind angle on the xy-plane \n",
    "        for il in range(12):\n",
    "            ts_dspk_wind_ang[ih,il] = get_wind_ang(ux_dspk[ih,:,il],uy_dspk[ih,:,il],1)\n",
    "            if np.logical_and(ts_dspk_wind_ang[ih,il]> min_wnd,ts_dspk_wind_ang[ih,il]<max_wnd):\n",
    "                qc_wdir_dspk[ih,il] = 1\n",
    "        # ts_dspk_wind_ang[ih,:],qc_wdir_dspk[ih,:] = wind_ang(ux_dspk[ih,:,:],uy_dspk[ih,:,:]) # 1*12, 1*12\n",
    "        \n",
    "        # 3. Double rotation\n",
    "        # start_time = time.time()\n",
    "        u_dspk_2rot,v_dspk_2rot,w_dspk_2rot = double_rot(ux_dspk[ih,:,:],uy_dspk[ih,:,:],uz_dspk[ih,:,:])\n",
    "        # print('2rot done')\n",
    "        # end_time = time.time()\n",
    "        # duration = end_time - start_time\n",
    "        # print(f\"Time taken for double rotation: {duration} seconds\")\n",
    "        \n",
    "        # Calculate mean variables\n",
    "        u_avg_dspk_2rot = np.nanmean(u_dspk_2rot,axis=0) # 12*1\n",
    "        v_avg_dspk_2rot = np.nanmean(v_dspk_2rot,axis=0)\n",
    "        w_avg_dspk_2rot = np.nanmean(w_dspk_2rot,axis=0)\n",
    "        T_avg_dspk = np.nanmean(T_dspk[ih,:,:],axis=0)\n",
    "          \n",
    "        # 4. Detrend\n",
    "        # start_time = time.time()\n",
    "        for il in range(12): # loop over levels\n",
    "            # if whole chunck is nan then skip detrend\n",
    "            if np.any([qc_ux_nan[ih,il],qc_uy_nan[ih,il],qc_uz_nan[ih,il],qc_T_nan[ih,il]]):\n",
    "                continue\n",
    "            else:\n",
    "                ## 4.1 Linear detrend\n",
    "                u_dspk_2rot_ldtr[ih,:,il] = dtrd(u_dspk_2rot[:,il])\n",
    "                v_dspk_2rot_ldtr[ih,:,il] = dtrd(v_dspk_2rot[:,il])\n",
    "                w_dspk_2rot_ldtr[ih,:,il] = dtrd(w_dspk_2rot[:,il])\n",
    "                T_dspk_ldtr[ih,:,il] = dtrd(T_dspk[ih,:,il])\n",
    "\n",
    "                ## 4.2 high-pass filter detrend\n",
    "                u_cutoff = u_avg_dspk_2rot[il]/l_cutoff     # desired cutoff frequency of the filter, Hz\n",
    "                # print(cutoff)\n",
    "                u_filt_size[ih,il] = int(1/u_cutoff) # seconds\n",
    "                # print(filt_size)\n",
    "                u_tur = u_dspk_2rot[:,il]-u_avg_dspk_2rot[il]\n",
    "                u_dspk_2rot_trend[ih,:,il] = butter_lowpass_filter('low', u_tur, u_cutoff, frequency, order)\n",
    "                u_dspk_2rot_filt[ih,:,il] = u_dspk_2rot[:,il]-u_dspk_2rot_trend[ih,:,il]\n",
    "                # print('1')\n",
    "                \n",
    "                v_tur = v_dspk_2rot[:,il]-v_avg_dspk_2rot[il]\n",
    "                v_dspk_2rot_trend[ih,:,il] = butter_lowpass_filter('low', v_tur, u_cutoff, frequency, order)\n",
    "                v_dspk_2rot_filt[ih,:,il] = v_dspk_2rot[:,il]-v_dspk_2rot_trend[ih,:,il]\n",
    "                # print('2')\n",
    "                \n",
    "                w_tur = w_dspk_2rot[:,il]-w_avg_dspk_2rot[il]\n",
    "                w_dspk_2rot_trend[ih,:,il] = butter_lowpass_filter('low', w_tur, u_cutoff, frequency, order)\n",
    "                w_dspk_2rot_filt[ih,:,il] = w_dspk_2rot[:,il]-w_dspk_2rot_trend[ih,:,il]\n",
    "                # print('3')\n",
    "                \n",
    "                T_tur = T_dspk[ih,:,il]-T_avg_dspk[il]\n",
    "                T_dspk_trend[ih,:,il] = butter_lowpass_filter('low', T_tur, u_cutoff, frequency, order)\n",
    "                T_dspk_filt[ih,:,il] = T_dspk[ih,:,il]-T_dspk_trend[ih,:,il]\n",
    "                breakpoint()\n",
    "        # end_time = time.time()\n",
    "        # duration = end_time - start_time\n",
    "        # print(f\"Time taken for detrending: {duration} seconds\")  \n",
    "        # print('detrend done') \n",
    "        \n",
    "        # 5. Calculate statistics (I will discard \"_dspk_2rot\" from now on)\n",
    "        # start_time = time.time()\n",
    "        ## Calculate mean variables\n",
    "        u_avg_ldtr[ih,:] = np.nanmean(u_dspk_2rot_ldtr[ih,:,:],axis=0) # 12*1\n",
    "        v_avg_ldtr[ih,:] = np.nanmean(v_dspk_2rot_ldtr[ih,:,:],axis=0)\n",
    "        w_avg_ldtr[ih,:] = np.nanmean(w_dspk_2rot_ldtr[ih,:,:],axis=0)\n",
    "        T_avg_ldtr[ih,:] = np.nanmean(T_dspk_ldtr[ih,:,:],axis=0)\n",
    "        \n",
    "        u_avg_filt[ih,:] = np.nanmean(u_dspk_2rot_filt[ih,:,:],axis=0) # 12*1\n",
    "        v_avg_filt[ih,:] = np.nanmean(v_dspk_2rot_filt[ih,:,:],axis=0)\n",
    "        w_avg_filt[ih,:] = np.nanmean(w_dspk_2rot_filt[ih,:,:],axis=0)\n",
    "        T_avg_filt[ih,:] = np.nanmean(T_dspk_filt[ih,:,:],axis=0)\n",
    "        # print('1')\n",
    "        \n",
    "        ## calculate turbulent variables (36000*12)\n",
    "        u_tur_ldtr[ih,:,:] = u_dspk_2rot_ldtr[ih,:,:] - u_avg_ldtr[ih,:]\n",
    "        v_tur_ldtr[ih,:,:] = v_dspk_2rot_ldtr[ih,:,:] - v_avg_ldtr[ih,:] \n",
    "        w_tur_ldtr[ih,:,:] = w_dspk_2rot_ldtr[ih,:,:] - w_avg_ldtr[ih,:]\n",
    "        T_tur_ldtr[ih,:,:] = T_dspk_ldtr[ih,:,:] - T_avg_ldtr[ih,:] \n",
    "        \n",
    "        u_tur_filt[ih,:,:] = u_dspk_2rot_filt[ih,:,:] - u_avg_filt[ih,:]\n",
    "        v_tur_filt[ih,:,:] = v_dspk_2rot_filt[ih,:,:] - v_avg_filt[ih,:]\n",
    "        w_tur_filt[ih,:,:] = w_dspk_2rot_filt[ih,:,:] - w_avg_filt[ih,:]\n",
    "        T_tur_filt[ih,:,:] = T_dspk_filt[ih,:,:] - T_avg_filt[ih,:]\n",
    "        \n",
    "        ## calculate standard deviations\n",
    "        u_std_ldtr[ih,:] = np.nanstd(u_tur_ldtr[ih,:,:],axis=0)\n",
    "        v_std_ldtr[ih,:] = np.nanstd(v_tur_ldtr[ih,:,:],axis=0)\n",
    "        w_std_ldtr[ih,:] = np.nanstd(w_tur_ldtr[ih,:,:],axis=0)\n",
    "        T_std_ldtr[ih,:] = np.nanstd(T_tur_ldtr[ih,:,:],axis=0)\n",
    "        \n",
    "        u_std_filt[ih,:] = np.nanstd(u_tur_filt[ih,:,:],axis=0)\n",
    "        v_std_filt[ih,:] = np.nanstd(v_tur_filt[ih,:,:],axis=0)\n",
    "        w_std_filt[ih,:] = np.nanstd(w_tur_filt[ih,:,:],axis=0)\n",
    "        T_std_filt[ih,:] = np.nanstd(T_tur_filt[ih,:,:],axis=0)\n",
    "        \n",
    "        ## calcultate covariance and fluxes\n",
    "        uw_ldtr[ih,:] = np.nanmean(u_tur_ldtr[ih,:,:]*w_tur_ldtr[ih,:,:],axis=0)\n",
    "        vw_ldtr[ih,:] = np.nanmean(v_tur_ldtr[ih,:,:]*w_tur_ldtr[ih,:,:],axis=0)\n",
    "        wT_ldtr[ih,:] = np.nanmean(w_tur_ldtr[ih,:,:]*T_tur_ldtr[ih,:,:],axis=0) # sensible heat flux\n",
    "        H_ldtr[ih,:]  = Cp*Rho_air[ih,:]*wT_ldtr[ih,:]\n",
    "        \n",
    "        uw_filt[ih,:] = np.nanmean(u_tur_filt[ih,:,:]*w_tur_filt[ih,:,:],axis=0)\n",
    "        vw_filt[ih,:] = np.nanmean(v_tur_filt[ih,:,:]*w_tur_filt[ih,:,:],axis=0)\n",
    "        wT_filt[ih,:] = np.nanmean(w_tur_filt[ih,:,:]*T_tur_filt[ih,:,:],axis=0) # sensible heat flux\n",
    "        H_filt[ih,:]  = Cp*Rho_air[ih,:]*wT_filt[ih,:]\n",
    "        \n",
    "        u_star_ldtr[ih,:] = np.maximum(0,(uw_ldtr[ih,:]**2+vw_ldtr[ih,:]**2)**0.25)\n",
    "        u_star_filt[ih,:] = np.maximum(0,(uw_filt[ih,:]**2+vw_filt[ih,:]**2)**0.25)\n",
    "        \n",
    "        # end_time = time.time()\n",
    "        # duration = end_time - start_time\n",
    "        # print(f\"Time taken for statistics: {duration} seconds\")\n",
    "        \n",
    "        # 6. calculate other variables\n",
    "        ## Obukhov length (m) without Evaporation term \n",
    "        ## results are very similar between _ldtr and _filt so only keep one\n",
    "        L_H2_ldtr[ih,:] = -u_star_ldtr[ih,:]**3*T_avg_ldtr[ih,:]/(k*g*wT_ldtr[ih,:]) \n",
    "        stability_ldtr[ih,:] = z/L_H2_ldtr[ih,:]\n",
    "        L_H2_filt[ih,:] = -u_star_filt[ih,:]**3*T_avg_filt[ih,:]/(k*g*wT_filt[ih,:]) \n",
    "        stability_filt[ih,:] = z/L_H2_filt[ih,:]\n",
    "    \n",
    "    if write_results:\n",
    "        print('start writing results')    \n",
    "        for var_name in out_tur+out_avg+out_std+out_flux+out_other+out_qf+out_nspikes:\n",
    "            # Access the variable by name using globals() - this allows you to get the variable's value by its name as a string\n",
    "            var_value = globals()[var_name]\n",
    "            # Construct the filename using the variable's name and the specified date, then save the array to a .npy file\n",
    "            filename = f\"{var_name}_{strday}.npy\"\n",
    "            np.save(OUT_DIR + filename, var_value)\n",
    "\n",
    "    print('finish:'+ strday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e35872-492e-41f7-b8aa-e7ba66507cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f45fdd32-9f4e-43d7-b4c3-d4b819c657ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1 = '20200925'\n",
    "dir1 = '/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/processed_data_020124/'\n",
    "a_file = open(dir1 + 'u_std_filt_' + day1 +'.pkl', \"rb\")\n",
    "u_std_filt1 = pickle.load(a_file)\n",
    "a_file.close()\n",
    "\n",
    "u_std_filt2 = np.load(OUT_DIR + 'u_std_filt_' + day1 +'.npy')\n",
    "u_std_filt1-u_std_filt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98396ea7-becf-4fc8-a330-76f685793b8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example: plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525b781-d346-469c-867b-0509b124355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4), dpi=150,tight_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f574e-48b9-4907-98fd-56f4f3ed2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4), dpi=150,tight_layout=True)\n",
    "ax1 = fig.add_subplot(121) \n",
    "plt.plot(u_std_filt[0,list_sel_m2])\n",
    "# plt.ylim(0,1.2)\n",
    "# plt.plot(u_star_ldtr)\n",
    "ax2 = fig.add_subplot(122) \n",
    "plt.plot(u_std_ldtr[0,list_sel_m2])\n",
    "# plt.ylim(0,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf70e7-7d72-46bb-9843-93914f3fb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4), dpi=150,tight_layout=True)\n",
    "plt.plot(L_H2_filt[:,1])\n",
    "plt.plot(L_H2_ldtr[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725d59e-e933-415d-a21e-49cb59c62085",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4), dpi=150,tight_layout=True)\n",
    "# plt.plot(u_2rot_dspk_filt[:,0])\n",
    "plt.plot(u_dspk_2rot_ldtr[:,0])\n",
    "plt.plot(u_dspk_2rot_filt[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cffe77-0864-4fa5-b458-03a182b1105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4), dpi=150,tight_layout=True)\n",
    "plt.plot(H_ldtr[0,:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
