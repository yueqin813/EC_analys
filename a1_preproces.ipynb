{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This first part pre-processes EC data and saves u,v,w,q,C,P,Tsonic and hourly averaged data with the desired format\n",
    "Note: GroupC data missing from date(2021,1,15) to date(2021,2,21), and date(2020,12,16)\\\n",
    "2021-8-24 created by Yue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Make sure the environment is good\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pickle\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.dates as dates\n",
    "from datetime import date, timedelta\n",
    "\n",
    "DATA_DIRECTORY = \"/projectnb/urbanclimate/public/Idaho_2020/tsdata/\" \n",
    "OUT_DIRECTORY = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/processed_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_list(sdate,edate):\n",
    "    \"\"\"method used for creating date list\"\"\"\n",
    "    delta = edate - sdate       # as timedelta\n",
    "    day = [sdate+timedelta(days=x) for x in range(delta.days+1)]\n",
    "    return day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonum    =12                       # number of sonic\n",
    "z        =[1.2,2,3.5,6,8.2,12.8,15.8,23,30.3,40.2,50.6,60.5];                 # height of sonic above ground, m\n",
    "frequency=10                   # sampling frequency, Hz\n",
    "time_avg =3600                  # average time, s\n",
    "i   = 1     # loop for number of files\n",
    "kd   = 1     # loop for saves in all files\n",
    "rpat = time_avg*frequency           # number of lines for a loop\n",
    "u_header=['Ux_C1','Ux_C2','Ux_C3','Ux_C4','Ux_B1','Ux_B2','Ux_B3','Ux_B4','Ux_A1','Ux_A2','Ux_A3','Ux_A4']\n",
    "v_header=['Uy_C1','Uy_C2','Uy_C3','Uy_C4','Uy_B1','Uy_B2','Uy_B3','Uy_B4','Uy_A1','Uy_A2','Uy_A3','Uy_A4']\n",
    "w_header=['Uz_C1','Uz_C2','Uz_C3','Uz_C4','Uz_B1','Uz_B2','Uz_B3','Uz_B4','Uz_A1','Uz_A2','Uz_A3','Uz_A4']\n",
    "Tsonic_header=['Ts_C1','Ts_C2','Ts_C3','Ts_C4','Ts_B1','Ts_B2','Ts_B3','Ts_B4','Ts_A1','Ts_A2','Ts_A3','Ts_A4']\n",
    "diag_header=['diag_sonic_C1','diag_sonic_C2','diag_sonic_C3','diag_sonic_C4','diag_sonic_B1','diag_sonic_B2','diag_sonic_B3','diag_sonic_B4',\n",
    "            'diag_sonic_A1','diag_sonic_A2','diag_sonic_A3','diag_sonic_A4']\n",
    "co2_header=['co2_C1','co2_C2','co2_C3','co2_C4','co2_B1','co2_B2','co2_B3','co2_B4','co2_A1','co2_A2','co2_A3','co2_A4']\n",
    "h2o_header=['h2o_C1','h2o_C2','h2o_C3','h2o_C4','h2o_B1','h2o_B2','h2o_B3','h2o_B4','h2o_A1','h2o_A2','h2o_A3','h2o_A4']\n",
    "sig_header=['sig_irga_C1','sig_irga_C2','sig_irga_C3','sig_irga_C4','sig_irga_B1','sig_irga_B2','sig_irga_B3',\n",
    "            'sig_irga_B4','sig_irga_A1','sig_irga_A2','sig_irga_A3','sig_irga_A4']\n",
    "press_header=['Press_irga_C1','Press_irga_C2','Press_irga_C3','Press_irga_C4','Press_irga_B1','Press_irga_B2','Press_irga_B3',\n",
    "            'Press_irga_B4','Press_irga_A1','Press_irga_A2','Press_irga_A3','Press_irga_A4']\n",
    "# print(len(month))\n",
    "\n",
    "out_var=['u_ins','v_ins','w_ins','q_ins','C_ins','P_ins','Tsonic_ins',\n",
    "         'diag_csat_ins','sig_irga_ins'] #,'date_num_ins']\n",
    "# out_var=['diag_csat_ins','sig_irga_ins']\n",
    "\n",
    "# set up saving controller\n",
    "do_saving = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute the total days as selected in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total day:38\n"
     ]
    }
   ],
   "source": [
    "d_total = 0\n",
    "# dys  = list(range(1,32))\n",
    "Sdate = date(2021,1,15)\n",
    "Edate = date(2021,2,21)\n",
    "ds = date_list(Sdate,Edate)\n",
    "for iday in range(len(ds)):\n",
    "    cyr = str(ds[iday].year)\n",
    "    if ds[iday].month < 10:\n",
    "        cmonth = '0'+ str(ds[iday].month)\n",
    "    else:\n",
    "        cmonth = str(ds[iday].month) \n",
    "    if ds[iday].day < 10:\n",
    "        cdys = '0'+ str(ds[iday].day)\n",
    "    else:\n",
    "        cdys = str(ds[iday].day)          \n",
    "# read in the input data            \n",
    "    fp_stats1 = DATA_DIRECTORY +'Group_C/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    fp_stats2 = DATA_DIRECTORY +'Group_B/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    fp_stats3 = DATA_DIRECTORY +'Group_A/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    if os.path.isfile(fp_stats2) & os.path.isfile(fp_stats3):\n",
    "    # if os.path.isfile(fp_stats1) & os.path.isfile(fp_stats2) & os.path.isfile(fp_stats2):\n",
    "        d_total += 1\n",
    "print('total day:'+str(d_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing:20210115\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210115\n",
      "elapsed time:8.13144326210022\n",
      "start processing:20210116\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210116\n",
      "elapsed time:8.19733738899231\n",
      "start processing:20210117\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210117\n",
      "elapsed time:8.057005882263184\n",
      "start processing:20210118\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210118\n",
      "elapsed time:8.835447788238525\n",
      "start processing:20210119\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210119\n",
      "elapsed time:8.297029733657837\n",
      "start processing:20210120\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210120\n",
      "elapsed time:8.229252576828003\n",
      "start processing:20210121\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210121\n",
      "elapsed time:8.364084720611572\n",
      "start processing:20210122\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210122\n",
      "elapsed time:9.164945363998413\n",
      "start processing:20210123\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210123\n",
      "elapsed time:9.081805944442749\n",
      "start processing:20210124\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210124\n",
      "elapsed time:9.056405305862427\n",
      "start processing:20210125\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210125\n",
      "elapsed time:9.128989458084106\n",
      "start processing:20210126\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210126\n",
      "elapsed time:9.12775731086731\n",
      "start processing:20210127\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210127\n",
      "elapsed time:9.083139419555664\n",
      "start processing:20210128\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210128\n",
      "elapsed time:8.990092992782593\n",
      "start processing:20210129\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210129\n",
      "elapsed time:8.92070198059082\n",
      "start processing:20210130\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210130\n",
      "elapsed time:9.009464502334595\n",
      "start processing:20210131\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210131\n",
      "elapsed time:9.048396825790405\n",
      "start processing:20210201\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210201\n",
      "elapsed time:9.068359375\n",
      "start processing:20210202\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210202\n",
      "elapsed time:8.87123990058899\n",
      "start processing:20210203\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210203\n",
      "elapsed time:8.948578119277954\n",
      "start processing:20210204\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210204\n",
      "elapsed time:9.145815372467041\n",
      "start processing:20210205\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210205\n",
      "elapsed time:8.967050790786743\n",
      "start processing:20210206\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210206\n",
      "elapsed time:8.913112163543701\n",
      "start processing:20210207\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210207\n",
      "elapsed time:9.047616958618164\n",
      "start processing:20210208\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210208\n",
      "elapsed time:9.052256345748901\n",
      "start processing:20210209\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210209\n",
      "elapsed time:9.06684422492981\n",
      "start processing:20210210\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210210\n",
      "elapsed time:9.047653436660767\n",
      "start processing:20210211\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210211\n",
      "elapsed time:9.070110082626343\n",
      "start processing:20210212\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210212\n",
      "elapsed time:9.039282321929932\n",
      "start processing:20210213\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210213\n",
      "elapsed time:8.95920729637146\n",
      "start processing:20210214\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210214\n",
      "elapsed time:8.642536640167236\n",
      "start processing:20210215\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210215\n",
      "elapsed time:8.900764226913452\n",
      "start processing:20210216\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210216\n",
      "elapsed time:8.964516401290894\n",
      "start processing:20210217\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210217\n",
      "elapsed time:8.915763139724731\n",
      "start processing:20210218\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210218\n",
      "elapsed time:9.234961032867432\n",
      "start processing:20210219\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210219\n",
      "elapsed time:9.09170150756836\n",
      "start processing:20210220\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210220\n",
      "elapsed time:9.127161741256714\n",
      "start processing:20210221\n",
      "diag_csat_ins\n",
      "sig_irga_ins\n",
      "finish:20210221\n",
      "elapsed time:9.040538787841797\n",
      "CPU times: user 4min 19s, sys: 1min 14s, total: 5min 33s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t_id = 0 # time index\n",
    "date_time = []\n",
    "for iday in range(len(ds)):\n",
    "    start = time.time()\n",
    "    cyr = str(ds[iday].year)\n",
    "    if ds[iday].month < 10:\n",
    "        cmonth = '0'+ str(ds[iday].month)\n",
    "    else:\n",
    "        cmonth = str(ds[iday].month) \n",
    "    if ds[iday].day < 10:\n",
    "        cdys = '0'+ str(ds[iday].day)\n",
    "    else:\n",
    "        cdys = str(ds[iday].day)          \n",
    "    # read in the input data            \n",
    "    fp_stats1 = DATA_DIRECTORY +'Group_C/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    fp_stats2 = DATA_DIRECTORY +'Group_B/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    fp_stats3 = DATA_DIRECTORY +'Group_A/ec_flux_' + cyr + cmonth + cdys + '_0000.dat'\n",
    "    if os.path.isfile(fp_stats2) & os.path.isfile(fp_stats3):\n",
    "    # if os.path.isfile(fp_stats1) & os.path.isfile(fp_stats2) & os.path.isfile(fp_stats2):\n",
    "        print('start processing:'+ cyr + cmonth + cdys)\n",
    "        # create an empty array for everyday;\n",
    "        u_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        v_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        w_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        Tsonic_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        diag_csat_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        C_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        q_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        sig_irga_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        P_ins = np.empty((rpat*24,sonum))*np.nan\n",
    "        date_num_ins = np.empty((rpat*24,3))*np.nan\n",
    "        date_num_ins[:,0]=ds[iday].year\n",
    "        date_num_ins[:,1]=ds[iday].month\n",
    "        date_num_ins[:,2]=ds[iday].day\n",
    "\n",
    "        # fid1=pd.read_csv(fp_stats1,sep=',',index_col=0,na_values=-9999)\n",
    "        fid2=pd.read_csv(fp_stats2,sep=',',index_col=0,na_values=-9999)\n",
    "        fid3=pd.read_csv(fp_stats3,sep=',',index_col=0,na_values=-9999)\n",
    "    else: \n",
    "        continue \n",
    "    date_time = fid2.index[round(rpat/2)-1::rpat]\n",
    "    # for j in range(3):\n",
    "    for j in [1,2]: # loop of files\n",
    "        fid = eval('fid'+str(j+1))\n",
    "        for i in range(4): # loop in order to change the order of column into the same as header\n",
    "            # u_ins[:,i+4*j] = fid[u_header[i+4*j]] # u velocity, m/s\n",
    "            # v_ins[:,i+4*j] = fid[v_header[i+4*j]] # v velocity, m/s\n",
    "            # w_ins[:,i+4*j] = fid[w_header[i+4*j]] # w velocity, m/s\n",
    "            # Tsonic_ins[:,i+4*j] = fid[Tsonic_header[i+4*j]] # sonic temperature, degC\n",
    "            diag_csat_ins[:,i+4*j] = fid[diag_header[i+4*j]] # diagnostic word for CSAT -- use to set flag\n",
    "            # if co2_header[i+4*j] in list(fid.columns):\n",
    "            #     C_ins[:,i+4*j]=fid[co2_header[i+4*j]] # CO2 density, mg/m3\n",
    "            # else:\n",
    "            #     C_ins[:,i+4*j]=np.nan\n",
    "            # if h2o_header[i+4*j] in list(fid.columns):\n",
    "            #     q_ins[:,i+4*j]=fid[h2o_header[i+4*j]] # water vapor density, g/m3\n",
    "            # else:\n",
    "            #     q_ins[:,i+4*j]=np.nan\n",
    "            if sig_header[i+4*j] in list(fid.columns):\n",
    "                sig_irga_ins[:,i+4*j]=fid[sig_header[i+4*j]]\n",
    "            else:\n",
    "                sig_irga_ins[:,i+4*j]=np.nan\n",
    "            # if press_header[i+4*j] in list(fid.columns):\n",
    "            #     P_ins[:,i+4*j]=fid[press_header[i+4*j]] # pressure, kPa\n",
    "            # else:\n",
    "            #     P_ins[:,i+4*j]=np.nan \n",
    "\n",
    "            ## change unit\n",
    "            q_ins  = q_ins*1e-3            # kg/m3\n",
    "            C_ins  = C_ins*1e-6            # kg/m3\n",
    "            Tsonic_ins = Tsonic_ins + 273.15       # K\n",
    "            P_ins  = P_ins*1e3             # Pa   \n",
    "\n",
    "    t_id += 1\n",
    "    # save results\n",
    "    if do_saving==1:\n",
    "        for var in out_var:\n",
    "        #     globals()[var].to_json(OUT_DIRECTORY + var +'_920.json')\n",
    "            a_file = open(OUT_DIRECTORY + var + '_' + cyr + cmonth + cdys +'.pkl', \"wb\")\n",
    "            pickle.dump(eval(var), a_file)\n",
    "            a_file.close()\n",
    "            print(var)\n",
    "        a_file = open(OUT_DIRECTORY + 'date_time_' + cyr + cmonth + cdys +'.pkl', \"wb\")\n",
    "        pickle.dump(date_time, a_file)\n",
    "        a_file.close()\n",
    "    print('finish:'+ cyr + cmonth + cdys)\n",
    "    end = time.time()\n",
    "    print('elapsed time:'+ str(end - start))\n",
    "# a_file = open(OUT_DIRECTORY + 'date_time.pkl', \"wb\")\n",
    "# pickle.dump(date_time, a_file)\n",
    "# a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   10  11\n",
       "0      NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "1      NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "2      NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "3      NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "4      NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "863995 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "863996 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "863997 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "863998 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "863999 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "\n",
       "[864000 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(u_ins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
