{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This third part is used for masking out unqualified data.\\\n",
    "neural case is defines as |Z/L|<0.1\\\n",
    "options: flux_magnitude_control, taylor_assumption_control, variance_control, angle_control, w_std_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pickle\n",
    "import time\n",
    "from matplotlib.pyplot import figure\n",
    "import scipy.io as sio\n",
    "from datetime import date, timedelta\n",
    "IN_DIRECTORY = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/basic_processed_data/\"\n",
    "IN_DIRECTORY2 = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/processed_data/\"\n",
    "OUT_DIRECTORY = \"/projectnb/urbanclimate/yueqin/idaho_ec_jupyter/mask_data/\"\n",
    "\n",
    "in_var1=['H','u_star','L_H2','rot_ang_v']\n",
    "in_var2=['u_std','u_avg','v_std','w_std','q_std','T_std']\n",
    "out_var = ['mask_INL_all_1d','mask_neutral','mask_INL_all','mask_INL_all_11',\n",
    "           'mask_INL_all_12','mask_INL_all_3','mask_INL_all_4','mask_INL_all_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defines functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_list(sdate,edate):\n",
    "    \"\"\"method used for creating date list\"\"\"\n",
    "    delta = edate - sdate       # as timedelta\n",
    "    day = [sdate+timedelta(days=x) for x in range(delta.days+1)]\n",
    "    return day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up controls\n",
    "flux_magnitude_control    = 1    \n",
    "taylor_assumption_control = 1    \n",
    "variance_control          = 0    \n",
    "angle_control             = 1 \n",
    "w_std_control             = 0\n",
    "do_saving = False\n",
    "\n",
    "# some constants to be used\n",
    "min_wnd                   = 120\n",
    "max_wnd                   = 240 \n",
    "sonum    =12                       # number of sonic\n",
    "z        =[1.2,2,3.5,6,8.2,12.8,15.8,23,30.3,40.2,50.6,60.5]                 # height of sonic above ground, m\n",
    "frequency=10                   # sampling frequency, Hz\n",
    "time_avg =3600                  # average time, s\n",
    "rpat = time_avg*frequency           # number of lines for a loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute and save masks day by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Sdate = date(2020,9,25)\n",
    "Edate = date(2021,4,23)\n",
    "ds = date_list(Sdate,Edate)\n",
    "t_id = 0\n",
    "for day in ds:\n",
    "    strday = str(day.strftime(\"%Y%m%d\"))\n",
    "    fp_stats = IN_DIRECTORY + 'u_ins_' + strday +'.pkl'\n",
    "    if (not os.path.isfile(fp_stats)):\n",
    "        print(day.strftime(\"%Y%m%d\")+' do not exist')\n",
    "        continue\n",
    "    print('start loading:'+ strday)\n",
    "    # load data\n",
    "    for var in in_var1+in_var2: \n",
    "        a_file = open(IN_DIRECTORY + var +'_' + strday +'.pkl', \"rb\")\n",
    "        globals()[var] = pickle.load(a_file)    \n",
    "        a_file.close() \n",
    "    # calculate stability parameter\n",
    "    z_o_L = np.zeros((len(L_H2),sonum))+np.nan\n",
    "    for i in range(sonum):\n",
    "        z_o_L[:,i]=z[i]/L_H2[:,i]\n",
    "    ## create maskes\n",
    "    mask_INL_all = np.zeros(np.shape(z_o_L))+1;   \n",
    "    mask_INL_all_1d = np.zeros(np.shape(z_o_L)[0])+1;\n",
    "    mask_INL_all_11 = np.zeros(np.shape(z_o_L))+1;  # H magnitude control\n",
    "    mask_INL_all_12 = np.zeros(np.shape(z_o_L))+1;  # ustar magnitude control\n",
    "    mask_INL_all_13 = np.zeros(np.shape(z_o_L))+1;  # LE magnitude control\n",
    "    mask_INL_all_3 = np.zeros(np.shape(z_o_L))+1; # variance control\n",
    "    mask_INL_all_4 = np.zeros(np.shape(z_o_L))+1; # angle control\n",
    "    mask_INL_all_5 = np.zeros(np.shape(z_o_L))+1; # w_std control\n",
    "    w_std_MOST = np.zeros(np.shape(z_o_L))+np.nan;\n",
    "    # create mask for neutral condition\n",
    "    mask_neutral = np.nanmax(abs(z_o_L),1)<0.1\n",
    "    if flux_magnitude_control == 1:\n",
    "        msk1 = abs(H)< 10\n",
    "        mask_INL_all[msk1]= np.nan\n",
    "        mask_INL_all_11[msk1]= np.nan\n",
    "        msk2 = abs(u_star)<0.05\n",
    "        mask_INL_all[msk2]= np.nan\n",
    "        mask_INL_all_12[msk2]= np.nan\n",
    "    if taylor_assumption_control == 1:\n",
    "        msk3 = np.logical_or(u_std/u_avg>0.5,v_std/u_avg>0.5)\n",
    "        mask_INL_all[msk3]= np.nan\n",
    "        mask_INL_all_12[msk3]= np.nan\n",
    "    if variance_control == 1:\n",
    "        msk4 = np.logical_or(T_std<0.01 , u_std<0.005 , v_std<0.005 , \\\n",
    "        w_std<0.005 , q_std<2.35e-5)\n",
    "        mask_INL_all[msk4] = np.nan\n",
    "        mask_INL_all_3[msk4] = np.nan\n",
    "    if angle_control == 1:\n",
    "        msk5 = np.logical_and(rot_ang_v> min_wnd,rot_ang_v<max_wnd)\n",
    "        mask_INL_all[msk5] = np.nan\n",
    "        mask_INL_all_4[msk5] = np.nan\n",
    "    if w_std_control == 1:\n",
    "        msk = z_o_L < 0\n",
    "        w_std_MOST[msk] = 1*(1-3*z_o_L[msk])^(1/3)\n",
    "        msk6 = abs(w_std/u_star - w_std_MOST)> 0.2*w_std_MOST\n",
    "        mask_INL_all[msk5] = np.nan\n",
    "        mask_INL_all_5[msk5] = np.nan\n",
    "    test=np.isnan(mask_INL_all)\n",
    "    # 1-dimensional version of mask_INL_all\n",
    "    mask_INL_all_1d[np.any(test,1)]= np.nan\n",
    "    if do_saving:\n",
    "        for var in out_var:\n",
    "            a_file = open(OUT_DIRECTORY + var + '_' + strday +'.pkl', \"wb\")\n",
    "            pickle.dump(eval(var), a_file)\n",
    "            a_file.close()\n",
    "    print('finish processing:'+ strday)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.isnan(mask_INL_all)\n",
    "mask_INL_all_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mask_INL_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test,1)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_INL_all_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_neutral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
